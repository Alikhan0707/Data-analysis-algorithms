{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 1,  1],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2],\n",
    "              [ 1,  5],\n",
    "              [ 1,  3],\n",
    "              [ 1,  0],\n",
    "              [ 1,  5],\n",
    "              [ 1, 10],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Подберите скорость обучения $\\eta$ и количество итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 2        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [6.4   9.925], MSE = 3047.75\n",
      "Iteration #10: W_new = [19.64736398  8.5432902 ], MSE = 375.01\n",
      "Iteration #20: W_new = [27.53837091  7.07445298], MSE = 200.16\n",
      "Iteration #30: W_new = [32.55677631  6.14032368], MSE = 122.97\n",
      "Iteration #40: W_new = [35.8557133   5.52625737], MSE = 86.52\n",
      "Iteration #50: W_new = [38.09032894  5.11030453], MSE = 68.23\n",
      "Iteration #60: W_new = [39.64568357  4.82078979], MSE = 58.54\n",
      "Iteration #70: W_new = [40.75523942  4.61425634], MSE = 53.14\n",
      "Iteration #80: W_new = [41.56464012  4.46359395], MSE = 49.99\n",
      "Iteration #90: W_new = [42.16715757  4.35144096], MSE = 48.08\n",
      "Iteration #100: W_new = [42.62398298  4.26640717], MSE = 46.87\n",
      "Iteration #110: W_new = [42.97616387  4.20085199], MSE = 46.09\n",
      "Iteration #120: W_new = [43.25180654  4.14954368], MSE = 45.56\n",
      "Iteration #130: W_new = [43.47052498  4.10883128], MSE = 45.2\n",
      "Iteration #140: W_new = [43.6462497   4.07612177], MSE = 44.94\n",
      "Iteration #150: W_new = [43.78903723  4.0495432 ], MSE = 44.75\n",
      "Iteration #160: W_new = [43.90625834  4.02772359], MSE = 44.61\n",
      "Iteration #170: W_new = [44.00339196  4.00964307], MSE = 44.51\n",
      "Iteration #180: W_new = [44.08456461  3.99453354], MSE = 44.43\n",
      "Iteration #190: W_new = [44.15292255  3.98180935], MSE = 44.37\n",
      "Iteration #200: W_new = [44.21089225  3.97101883], MSE = 44.32\n",
      "Iteration #210: W_new = [44.26036526  3.96180989], MSE = 44.28\n",
      "Iteration #220: W_new = [44.30283097  3.9539053 ], MSE = 44.24\n",
      "Iteration #230: W_new = [44.33947324  3.94708468], MSE = 44.22\n",
      "Iteration #240: W_new = [44.37124142  3.94117133], MSE = 44.2\n",
      "Iteration #250: W_new = [44.39890315  3.93602236], MSE = 44.18\n",
      "Iteration #260: W_new = [44.42308404  3.93152131], MSE = 44.16\n",
      "Iteration #270: W_new = [44.44429767  3.92757259], MSE = 44.15\n",
      "Iteration #280: W_new = [44.46296862  3.92409717], MSE = 44.14\n",
      "Iteration #290: W_new = [44.47945015  3.92102928], MSE = 44.13\n",
      "Iteration #300: W_new = [44.49403803  3.91831389], MSE = 44.12\n",
      "Iteration #310: W_new = [44.5069813   3.91590462], MSE = 44.12\n",
      "Iteration #320: W_new = [44.5184908   3.91376223], MSE = 44.11\n",
      "Iteration #330: W_new = [44.52874595  3.91185333], MSE = 44.1\n",
      "Iteration #340: W_new = [44.53790018  3.91014936], MSE = 44.1\n",
      "Iteration #350: W_new = [44.54608526  3.90862578], MSE = 44.1\n",
      "Iteration #360: W_new = [44.55341485  3.90726145], MSE = 44.09\n",
      "Iteration #370: W_new = [44.55998737  3.90603803], MSE = 44.09\n",
      "Iteration #380: W_new = [44.56588838  3.90493962], MSE = 44.09\n",
      "Iteration #390: W_new = [44.57119249  3.9039523 ], MSE = 44.08\n",
      "Iteration #400: W_new = [44.57596501  3.90306394], MSE = 44.08\n",
      "Iteration #410: W_new = [44.58026323  3.90226387], MSE = 44.08\n",
      "Iteration #420: W_new = [44.58413759  3.9015427 ], MSE = 44.08\n",
      "Iteration #430: W_new = [44.58763259  3.90089213], MSE = 44.08\n",
      "Iteration #440: W_new = [44.59078759  3.90030486], MSE = 44.07\n",
      "Iteration #450: W_new = [44.59363749  3.89977438], MSE = 44.07\n",
      "Iteration #460: W_new = [44.5962133   3.89929492], MSE = 44.07\n",
      "Iteration #470: W_new = [44.5985426   3.89886134], MSE = 44.07\n",
      "Iteration #480: W_new = [44.60065     3.89846906], MSE = 44.07\n",
      "Iteration #490: W_new = [44.60255748  3.89811401], MSE = 44.07\n",
      "Iteration #500: W_new = [44.60428467  3.8977925 ], MSE = 44.07\n",
      "Iteration #510: W_new = [44.6058492   3.89750128], MSE = 44.07\n",
      "Iteration #520: W_new = [44.60726683  3.8972374 ], MSE = 44.07\n",
      "Iteration #530: W_new = [44.60855175  3.89699823], MSE = 44.07\n",
      "Iteration #540: W_new = [44.6097167   3.89678138], MSE = 44.07\n",
      "Iteration #550: W_new = [44.61077314  3.89658474], MSE = 44.07\n",
      "Iteration #560: W_new = [44.61173139  3.89640637], MSE = 44.06\n",
      "Iteration #570: W_new = [44.61260075  3.89624454], MSE = 44.06\n",
      "Iteration #580: W_new = [44.61338962  3.8960977 ], MSE = 44.06\n",
      "Iteration #590: W_new = [44.61410556  3.89596444], MSE = 44.06\n",
      "Iteration #600: W_new = [44.61475543  3.89584347], MSE = 44.06\n",
      "Iteration #610: W_new = [44.61534539  3.89573365], MSE = 44.06\n",
      "Iteration #620: W_new = [44.61588105  3.89563395], MSE = 44.06\n",
      "Iteration #630: W_new = [44.61636745  3.89554341], MSE = 44.06\n",
      "Iteration #640: W_new = [44.61680916  3.89546119], MSE = 44.06\n",
      "Iteration #650: W_new = [44.61721035  3.89538651], MSE = 44.06\n",
      "Iteration #660: W_new = [44.61757474  3.89531868], MSE = 44.06\n",
      "Iteration #670: W_new = [44.61790575  3.89525707], MSE = 44.06\n",
      "Iteration #680: W_new = [44.61820645  3.89520109], MSE = 44.06\n",
      "Iteration #690: W_new = [44.61847964  3.89515024], MSE = 44.06\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "\n",
    "# eta = 1e-8\n",
    "eta = 1e-2\n",
    "# n_iter = 100\n",
    "n_iter = 700\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for k in range(W.shape[0]):\n",
    "#         W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "#         Заменил eta на eta/(k+1)\n",
    "        W[k] -= eta/(k+1) * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        eta /= 1.1\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2*. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 2        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [ 6.4  19.35], MSE = 3047.75\n",
      "Iteration #10: W_new = [19.96966932  8.87179137], MSE = 379.6\n",
      "Iteration #20: W_new = [29.27719328  6.70531799], MSE = 172.93\n",
      "Iteration #30: W_new = [35.16120834  5.60976141], MSE = 94.66\n",
      "Iteration #40: W_new = [38.85365942  4.93848587], MSE = 63.9\n",
      "Iteration #50: W_new = [41.16920131  4.51849616], MSE = 51.81\n",
      "Iteration #60: W_new = [42.62118483  4.25519525], MSE = 47.05\n",
      "Iteration #70: W_new = [43.53165976  4.0900943 ], MSE = 45.18\n",
      "Iteration #80: W_new = [44.10257814  3.98656703], MSE = 44.45\n",
      "Iteration #90: W_new = [44.46057568  3.9216497 ], MSE = 44.16\n",
      "Iteration #100: W_new = [44.68506002  3.88094292], MSE = 44.04\n",
      "Iteration #110: W_new = [44.82582417  3.85541751], MSE = 44.0\n",
      "Iteration #120: W_new = [44.91409111  3.83941166], MSE = 43.98\n",
      "Iteration #130: W_new = [44.96943938  3.82937511], MSE = 43.97\n",
      "Iteration #140: W_new = [45.00414582  3.82308163], MSE = 43.97\n",
      "Iteration #150: W_new = [45.02590869  3.81913527], MSE = 43.97\n",
      "Iteration #160: W_new = [45.03955522  3.81666068], MSE = 43.97\n",
      "Iteration #170: W_new = [45.04811235  3.81510898], MSE = 43.97\n",
      "Iteration #180: W_new = [45.05347814  3.81413597], MSE = 43.97\n",
      "Iteration #190: W_new = [45.05684279  3.81352585], MSE = 43.97\n",
      "Iteration #200: W_new = [45.05895262  3.81314326], MSE = 43.97\n",
      "Iteration #210: W_new = [45.06027559  3.81290336], MSE = 43.97\n",
      "Iteration #220: W_new = [45.06110517  3.81275293], MSE = 43.97\n",
      "Iteration #230: W_new = [45.06162537  3.8126586 ], MSE = 43.97\n",
      "Iteration #240: W_new = [45.06195156  3.81259945], MSE = 43.97\n",
      "Iteration #250: W_new = [45.0621561   3.81256236], MSE = 43.97\n",
      "Iteration #260: W_new = [45.06228435  3.8125391 ], MSE = 43.97\n",
      "Iteration #270: W_new = [45.06236478  3.81252452], MSE = 43.97\n",
      "Iteration #280: W_new = [45.06241521  3.81251538], MSE = 43.97\n",
      "Iteration #290: W_new = [45.06244683  3.81250964], MSE = 43.97\n",
      "Iteration #300: W_new = [45.06246666  3.81250605], MSE = 43.97\n",
      "Iteration #310: W_new = [45.06247909  3.81250379], MSE = 43.97\n",
      "Iteration #320: W_new = [45.06248689  3.81250238], MSE = 43.97\n",
      "Iteration #330: W_new = [45.06249178  3.81250149], MSE = 43.97\n",
      "Iteration #340: W_new = [45.06249485  3.81250093], MSE = 43.97\n",
      "Iteration #350: W_new = [45.06249677  3.81250059], MSE = 43.97\n",
      "Iteration #360: W_new = [45.06249797  3.81250037], MSE = 43.97\n",
      "Iteration #370: W_new = [45.06249873  3.81250023], MSE = 43.97\n",
      "Iteration #380: W_new = [45.0624992   3.81250014], MSE = 43.97\n",
      "Iteration #390: W_new = [45.0624995   3.81250009], MSE = 43.97\n",
      "Iteration #400: W_new = [45.06249969  3.81250006], MSE = 43.97\n",
      "Iteration #410: W_new = [45.0624998   3.81250004], MSE = 43.97\n",
      "Iteration #420: W_new = [45.06249988  3.81250002], MSE = 43.97\n",
      "Iteration #430: W_new = [45.06249992  3.81250001], MSE = 43.97\n",
      "Iteration #440: W_new = [45.06249995  3.81250001], MSE = 43.97\n",
      "Iteration #450: W_new = [45.06249997  3.81250001], MSE = 43.97\n",
      "Iteration #460: W_new = [45.06249998  3.8125    ], MSE = 43.97\n",
      "Iteration #470: W_new = [45.06249999  3.8125    ], MSE = 43.97\n",
      "Iteration #480: W_new = [45.06249999  3.8125    ], MSE = 43.97\n",
      "Iteration #490: W_new = [45.0625  3.8125], MSE = 43.97\n",
      "Iteration #500: W_new = [45.0625  3.8125], MSE = 43.97\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "\n",
    "# eta = 1e-1 \n",
    "# n_iter = 2000\n",
    "\n",
    "eta = 1e-2\n",
    "n_iter = 510\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#     for k in range(W.shape[0]):\n",
    "#         W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "    # ИЗМЕНЕНИЯ\n",
    "#     W -= eta * (1/n * 2 * np.dot(X, y_pred - y))\n",
    "    # Заменил матрицу Х на Х.Т\n",
    "#     W -= eta/(i+1) * (1/n * 2 * np.dot(X.T, y_pred - y))\n",
    "    W -= eta * (1/n * 2 * np.dot(X.T, y_pred - y))\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3*. Вместо того, чтобы задавать количество итераций, задайте другое условие останова алгоритма - когда веса перестают изменяться меньше определенного порога $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: error - 3352.5, weights: [ 5.65 20.  ]\n",
      "Iter 1: error - 2223.9725000000008, weights: [4.735 4.305]\n",
      "Iter 2: error - 1555.2317000000005, weights: [ 8.62  15.566]\n",
      "Iter 3: error - 1150.523972, weights: [8.7382 6.5178]\n",
      "Iter 4: error - 898.2317652800004, weights: [11.55904 12.81608]\n",
      "Iter 5: error - 734.6397855296002, weights: [12.208312  7.561032]\n",
      "Iter 6: error - 623.3119354626563, weights: [14.3691712 11.044784 ]\n",
      "Iter 7: error - 543.3527996661862, weights: [15.26881888  7.95789984]\n",
      "Iter 8: error - 482.7256361621147, weights: [17.00456704  9.84882445]\n",
      "Iter 9: error - 434.4482501729789, weights: [17.999463    8.00445277]\n",
      "Iter 10: error - 394.42684046956845, weights: [19.44818087  8.99704416]\n",
      "Iter 11: error - 360.2221510052891, weights: [20.45424953  7.86761483]\n",
      "Iter 12: error - 330.34630938840354, weights: [21.69854013  8.35639476]\n",
      "Iter 13: error - 303.8617748136954, weights: [22.67176769  7.64096163]\n",
      "Iter 14: error - 280.1522999373207, weights: [23.76230243  7.84979655]\n",
      "Iter 15: error - 258.79185984381513, weights: [24.68113322  7.37645168]\n",
      "Iter 16: error - 239.46940028133918, weights: [25.6500844   7.43214385]\n",
      "Iter 17: error - 221.9454122733483, weights: [26.5054328   7.10247398]\n",
      "Iter 18: error - 206.02667305870924, weights: [27.37414733  7.07663837]\n",
      "Iter 19: error - 191.55137440438588, weights: [28.16374108  6.83410894]\n",
      "Iter 20: error - 178.38020680485627, weights: [28.94713429  6.76700142]\n",
      "Iter 21: error - 166.39087357995365, weights: [29.67232044  6.57895872]\n",
      "Iter 22: error - 155.47459369069384, weights: [30.38140078  6.49303276]\n",
      "Iter 23: error - 145.53376979837898, weights: [31.04535087  6.34045683]\n",
      "Iter 24: error - 136.48034993234518, weights: [31.68867873  6.24807496]\n",
      "Iter 25: error - 128.23461163639118, weights: [32.29538837  6.11974391]\n",
      "Iter 26: error - 120.72421181693126, weights: [32.87992636  6.02756275]\n",
      "Iter 27: error - 113.88341081675303, weights: [33.4336649   5.91672817]\n",
      "Iter 28: error - 107.65241660289732, weights: [33.96527996  5.82819081]\n",
      "Iter 29: error - 101.97681640488335, weights: [34.47029472  5.73068244]\n",
      "Iter 30: error - 96.80707551228537, weights: [34.95406052  5.64743387]\n",
      "Iter 31: error - 92.09809013389072, weights: [35.4144243   5.56057813]\n",
      "Iter 32: error - 87.8087854525896, weights: [35.85480843  5.48326802]\n",
      "Iter 33: error - 83.9017525444237, weights: [36.27434718  5.40526986]\n",
      "Iter 34: error - 80.34291938712454, weights: [36.67533151  5.33400694]\n",
      "Iter 35: error - 77.1012521739151, weights: [37.05759627  5.26359569]\n",
      "Iter 36: error - 74.14848380710903, weights: [37.42275794  5.19820414]\n",
      "Iter 37: error - 71.45886690756369, weights: [37.77102091  5.13442972]\n",
      "Iter 38: error - 69.00894901758899, weights: [38.1035899   5.07459292]\n",
      "Iter 39: error - 66.7773679411507, weights: [38.42085303  5.01670798]\n",
      "Iter 40: error - 64.74466538218492, weights: [38.72375533  4.9620485 ]\n",
      "Iter 41: error - 62.89311722494112, weights: [39.01276525  4.90943945]\n",
      "Iter 42: error - 61.206578958788214, weights: [39.28865689  4.85956281]\n",
      "Iter 43: error - 59.670344889597075, weights: [39.55192236  4.81170897]\n",
      "Iter 44: error - 58.27101990436786, weights: [39.80321743  4.76622702]\n",
      "Iter 45: error - 56.99640266769732, weights: [40.04302758  4.72267586]\n",
      "Iter 46: error - 55.8353792297677, weights: [40.27192207  4.68121862]\n",
      "Iter 47: error - 54.77782611712193, weights: [40.49036427  4.64157034]\n",
      "Iter 48: error - 53.81452206062888, weights: [40.69885674  4.60379148]\n",
      "Iter 49: error - 52.93706759061471, weights: [40.89783363  4.56768894]\n",
      "Iter 50: error - 52.137811797879785, weights: [41.08774358  4.53326765]\n",
      "Iter 51: error - 51.40978562188737, weights: [41.26898893  4.50038957]\n",
      "Iter 52: error - 50.74664108437248, weights: [41.44197316  4.46903062]\n",
      "Iter 53: error - 50.142595938484845, weights: [41.60706666  4.43908661]\n",
      "Iter 54: error - 49.592383250818855, weights: [41.76463401  4.41051937]\n",
      "Iter 55: error - 49.091205476701376, weights: [41.9150148   4.38324624]\n",
      "Iter 56: error - 48.63469262829354, weights: [42.05853945  4.3572232 ]\n",
      "Iter 57: error - 48.218864170752454, weights: [42.19551854  4.33238193]\n",
      "Iter 58: error - 47.84009431420624, weights: [42.32625211  4.30867709]\n",
      "Iter 59: error - 47.49508039890716, weights: [42.45102377  4.28605041]\n",
      "Iter 60: error - 47.18081409789811, weights: [42.57010627  4.26445758]\n",
      "Iter 61: error - 46.89455518609572, weights: [42.68375837  4.24384781]\n",
      "Iter 62: error - 46.633807647071286, weights: [42.79222819  4.22417902]\n",
      "Iter 63: error - 46.39629790919349, weights: [42.89575167  4.20540623]\n",
      "Iter 64: error - 46.17995502136459, weights: [42.99455463  4.18749014]\n",
      "Iter 65: error - 45.982892595493695, weights: [43.08885213  4.17039051]\n",
      "Iter 66: error - 45.80339235825528, weights: [43.17884976  4.154071  ]\n",
      "Iter 67: error - 45.639889168713864, weights: [43.26474348  4.13849537]\n",
      "Iter 68: error - 45.490957371177, weights: [43.34672052  4.1236302 ]\n",
      "Iter 69: error - 45.35529836428067, weights: [43.42495941  4.10944271]\n",
      "Iter 70: error - 45.23172927791724, weights: [43.49963066  4.09590228]\n",
      "Iter 71: error - 45.119172659274426, weights: [43.57089691  4.0829792 ]\n",
      "Iter 72: error - 45.01664707805384, weights: [43.63891346  4.07064548]\n",
      "Iter 73: error - 44.92325856895183, weights: [43.70382847  4.05887412]\n",
      "Iter 74: error - 44.83819283678559, weights: [43.76578338  4.04763957]\n",
      "Iter 75: error - 44.760708156298065, weights: [43.82491317  4.03691728]\n",
      "Iter 76: error - 44.690128904731466, weights: [43.88134667  4.02668395]\n",
      "Iter 77: error - 44.625839670777644, weights: [43.93520682  4.01691723]\n",
      "Iter 78: error - 44.567279888538145, weights: [43.98661097  4.00759589]\n",
      "Iter 79: error - 44.51393894970531, weights: [44.0356711   3.99869959]\n",
      "Iter 80: error - 44.46535175134569, weights: [44.08249412  3.99020896]\n",
      "Iter 81: error - 44.42109464046438, weights: [44.12718202  3.98210549]\n",
      "Iter 82: error - 44.380781719989685, weights: [44.16983217  3.97437155]\n",
      "Iter 83: error - 44.34406148396799, weights: [44.21053748  3.96699027]\n",
      "Iter 84: error - 44.310613752629976, weights: [44.24938666  3.95994557]\n",
      "Iter 85: error - 44.280146880603354, weights: [44.28646432  3.95322211]\n",
      "Iter 86: error - 44.252395213929596, weights: [44.32185126  3.94680523]\n",
      "Iter 87: error - 44.22711677371101, weights: [44.35562456  3.94068096]\n",
      "Iter 88: error - 44.204091146191196, weights: [44.38785782  3.93483596]\n",
      "Iter 89: error - 44.183117560871196, weights: [44.41862125  3.92925748]\n",
      "Iter 90: error - 44.164013139903844, weights: [44.44798188  3.92393339]\n",
      "Iter 91: error - 44.14661130350207, weights: [44.47600367  3.91885207]\n",
      "Iter 92: error - 44.1307603174569, weights: [44.50274769  3.91400245]\n",
      "Iter 93: error - 44.116321970100735, weights: [44.52827218  3.90937398]\n",
      "Iter 94: error - 44.10317036717943, weights: [44.55263277  3.90495656]\n",
      "Iter 95: error - 44.09119083412535, weights: [44.57588253  3.90074058]\n",
      "Iter 96: error - 44.08027891615969, weights: [44.5980721   3.89671684]\n",
      "Iter 97: error - 44.07033946750577, weights: [44.61924984  3.89287658]\n",
      "Iter 98: error - 44.06128582177134, weights: [44.63946188  3.88921144]\n",
      "Iter 99: error - 44.0530390362666, weights: [44.65875226  3.88571343]\n",
      "Iter 100: error - 44.0455272036683, weights: [44.67716301  3.88237492]\n",
      "Iter 101: error - 44.0386848250285, weights: [44.69473423  3.87918865]\n",
      "Iter 102: error - 44.03245223866052, weights: [44.71150421  3.87614767]\n",
      "Iter 103: error - 44.02677509992279, weights: [44.72750949  3.87324536]\n",
      "Iter 104: error - 44.02160390736412, weights: [44.74278493  3.8704754 ]\n",
      "Iter 105: error - 44.016893571098926, weights: [44.75736382  3.86783174]\n",
      "Iter 106: error - 44.01260301964885, weights: [44.77127791  3.86530864]\n",
      "Iter 107: error - 44.00869484182262, weights: [44.78455753  3.86290058]\n",
      "Iter 108: error - 44.0051349605115, weights: [44.7972316   3.86060233]\n",
      "Iter 109: error - 44.00189233555618, weights: [44.80932774  3.85840889]\n",
      "Iter 110: error - 43.99893869309398, weights: [44.8208723   3.85631546]\n",
      "Iter 111: error - 43.99624827902677, weights: [44.83189043  3.85431749]\n",
      "Iter 112: error - 43.993797634459696, weights: [44.84240614  3.85241063]\n",
      "Iter 113: error - 43.99156539115288, weights: [44.85244234  3.85059072]\n",
      "Iter 114: error - 43.989532085202356, weights: [44.86202089  3.8488538 ]\n",
      "Iter 115: error - 43.987679987325826, weights: [44.87116266  3.84719608]\n",
      "Iter 116: error - 43.98599294827332, weights: [44.87988758  3.84561395]\n",
      "Iter 117: error - 43.984456258014816, weights: [44.88821463  3.84410396]\n",
      "Iter 118: error - 43.98305651747704, weights: [44.89616198  3.84266284]\n",
      "Iter 119: error - 43.98178152171113, weights: [44.90374693  3.84128742]\n",
      "Iter 120: error - 43.98062015347237, weights: [44.91098601  3.83997473]\n",
      "Iter 121: error - 43.979562286284064, weights: [44.91789499  3.83872189]\n",
      "Iter 122: error - 43.97859869614034, weights: [44.92448893  3.83752618]\n",
      "Iter 123: error - 43.97772098107804, weights: [44.93078218  3.836385  ]\n",
      "Iter 124: error - 43.976921487916336, weights: [44.93678846  3.83529585]\n",
      "Iter 125: error - 43.976193245525344, weights: [44.94252086  3.83425637]\n",
      "Iter 126: error - 43.975529904041665, weights: [44.94799187  3.83326428]\n",
      "Iter 127: error - 43.97492567950133, weights: [44.95321339  3.83231744]\n",
      "Iter 128: error - 43.974375303406774, weights: [44.95819682  3.83141377]\n",
      "Iter 129: error - 43.97387397678854, weights: [44.96295301  3.83055131]\n",
      "Iter 130: error - 43.97341732836096, weights: [44.96749231  3.82972818]\n",
      "Iter 131: error - 43.97300137640704, weights: [44.97182463  3.82894258]\n",
      "Iter 132: error - 43.97262249406009, weights: [44.97595939  3.8281928 ]\n",
      "Iter 133: error - 43.97227737767954, weights: [44.97990561  3.82747722]\n",
      "Iter 134: error - 43.97196301804496, weights: [44.98367188  3.82679426]\n",
      "Iter 135: error - 43.97167667411747, weights: [44.98726642  3.82614245]\n",
      "Iter 136: error - 43.971415849139355, weights: [44.99069704  3.82552036]\n",
      "Iter 137: error - 43.97117826886373, weights: [44.99397123  3.82492664]\n",
      "Iter 138: error - 43.97096186172448, weights: [44.99709611  3.82435999]\n",
      "Iter 139: error - 43.970764740773284, weights: [45.00007851  3.82381918]\n",
      "Iter 140: error - 43.97058518722649, weights: [45.0029249   3.82330303]\n",
      "Iter 141: error - 43.97042163547833, weights: [45.00564151  3.82281041]\n",
      "Iter 142: error - 43.97027265944972, weights: [45.00823423  3.82234026]\n",
      "Iter 143: error - 43.97013696015362, weights: [45.01070873  3.82189155]\n",
      "Iter 144: error - 43.97001335436862, weights: [45.01307039  3.8214633 ]\n",
      "Iter 145: error - 43.96990076432191, weights: [45.01532437  3.82105457]\n",
      "Iter 146: error - 43.969798208291756, weights: [45.01747556  3.82066449]\n",
      "Iter 147: error - 43.9697047920473, weights: [45.01952865  3.82029219]\n",
      "Iter 148: error - 43.96961970105157, weights: [45.02148813  3.81993687]\n",
      "Iter 149: error - 43.96954219335901, weights: [45.02335826  3.81959775]\n",
      "Iter 150: error - 43.96947159314619, weights: [45.02514311  3.8192741 ]\n",
      "Iter 151: error - 43.96940728481905, weights: [45.02684657  3.8189652 ]\n",
      "Iter 152: error - 43.96934870764522, weights: [45.02847235  3.81867039]\n",
      "Iter 153: error - 43.969295350864726, weights: [45.030024    3.81838902]\n",
      "Iter 154: error - 43.9692467492365, weights: [45.03150489  3.81812049]\n",
      "Iter 155: error - 43.969202478981764, weights: [45.03291826  3.81786419]\n",
      "Iter 156: error - 43.96916215408881, weights: [45.03426717  3.81761959]\n",
      "Iter 157: error - 43.96912542294727, weights: [45.03555458  3.81738614]\n",
      "Iter 158: error - 43.96909196528234, weights: [45.03678328  3.81716333]\n",
      "Iter 159: error - 43.969061489361984, weights: [45.03795595  3.81695068]\n",
      "Iter 160: error - 43.969033729453386, weights: [45.03907515  3.81674773]\n",
      "Iter 161: error - 43.96900844350575, weights: [45.04014332  3.81655404]\n",
      "Iter 162: error - 43.96898541103989, weights: [45.04116277  3.81636918]\n",
      "Iter 163: error - 43.96896443122563, weights: [45.04213574  3.81619274]\n",
      "Iter 164: error - 43.96894532113087, weights: [45.04306435  3.81602436]\n",
      "Iter 165: error - 43.96892791412632, weights: [45.0439506   3.81586365]\n",
      "Iter 166: error - 43.9689120584327, weights: [45.04479645  3.81571027]\n",
      "Iter 167: error - 43.96889761579733, weights: [45.04560372  3.81556388]\n",
      "Iter 168: error - 43.96888446028853, weights: [45.04637419  3.81542417]\n",
      "Iter 169: error - 43.96887247719769, weights: [45.04710952  3.81529083]\n",
      "Iter 170: error - 43.968861562039, weights: [45.04781132  3.81516357]\n",
      "Iter 171: error - 43.968851619638436, weights: [45.04848112  3.81504211]\n",
      "Iter 172: error - 43.96884256330387, weights: [45.04912037  3.81492619]\n",
      "Iter 173: error - 43.96883431406916, weights: [45.04973048  3.81481556]\n",
      "Iter 174: error - 43.968826800005644, weights: [45.05031276  3.81470997]\n",
      "Iter 175: error - 43.96881995559489, weights: [45.0508685   3.81460919]\n",
      "Iter 176: error - 43.96881372115751, weights: [45.05139889  3.81451302]\n",
      "Iter 177: error - 43.968808042332725, weights: [45.0519051   3.81442122]\n",
      "Iter 178: error - 43.968802869604374, weights: [45.05238822  3.81433362]\n",
      "Iter 179: error - 43.968798157869195, weights: [45.05284931  3.81425   ]\n",
      "Iter 180: error - 43.9687938660435, weights: [45.05328938  3.8141702 ]\n",
      "Iter 181: error - 43.96878995670498, weights: [45.05370938  3.81409404]\n",
      "Iter 182: error - 43.96878639576644, weights: [45.05411023  3.81402136]\n",
      "Iter 183: error - 43.96878315217846, weights: [45.0544928   3.81395198]\n",
      "Iter 184: error - 43.9687801976588, weights: [45.05485793  3.81388577]\n",
      "Iter 185: error - 43.968777506445726, weights: [45.0552064   3.81382258]\n",
      "Iter 186: error - 43.96877505507333, weights: [45.05553899  3.81376227]\n",
      "Iter 187: error - 43.96877282216706, weights: [45.05585641  3.81370471]\n",
      "Iter 188: error - 43.968770788257245, weights: [45.05615935  3.81364978]\n",
      "Iter 189: error - 43.96876893560932, weights: [45.05644848  3.81359735]\n",
      "Iter 190: error - 43.96876724806924, weights: [45.05672443  3.81354731]\n",
      "Iter 191: error - 43.9687657109226, weights: [45.05698779  3.81349955]\n",
      "Iter 192: error - 43.96876431076636, weights: [45.05723915  3.81345397]\n",
      "Iter 193: error - 43.96876303539192, weights: [45.05747904  3.81341047]\n",
      "Iter 194: error - 43.96876187367878, weights: [45.057708    3.81336896]\n",
      "Iter 195: error - 43.96876081549741, weights: [45.05792651  3.81332933]\n",
      "Iter 196: error - 43.968759851621094, weights: [45.05813506  3.81329151]\n",
      "Iter 197: error - 43.968758973645365, weights: [45.0583341   3.81325542]\n",
      "Iter 198: error - 43.96875817391476, weights: [45.05852406  3.81322098]\n",
      "Iter 199: error - 43.96875744545609, weights: [45.05870536  3.8131881 ]\n",
      "Iter 200: error - 43.968756781917605, weights: [45.0588784   3.81315672]\n",
      "Iter 201: error - 43.96875617751361, weights: [45.05904354  3.81312678]\n",
      "Iter 202: error - 43.96875562697407, weights: [45.05920115  3.81309819]\n",
      "Iter 203: error - 43.96875512549855, weights: [45.05935158  3.81307092]\n",
      "Iter 204: error - 43.9687546687145, weights: [45.05949515  3.81304488]\n",
      "Iter 205: error - 43.96875425263902, weights: [45.05963217  3.81302004]\n",
      "Iter 206: error - 43.96875387364415, weights: [45.05976294  3.81299632]\n",
      "Iter 207: error - 43.96875352842527, weights: [45.05988775  3.81297369]\n",
      "Iter 208: error - 43.96875321397227, weights: [45.06000687  3.81295209]\n",
      "Iter 209: error - 43.96875292754329, weights: [45.06012055  3.81293148]\n",
      "Iter 210: error - 43.96875266664087, weights: [45.06022905  3.8129118 ]\n",
      "Iter 211: error - 43.96875242899004, weights: [45.06033261  3.81289302]\n",
      "Iter 212: error - 43.96875221251862, weights: [45.06043144  3.8128751 ]\n",
      "Iter 213: error - 43.96875201533912, weights: [45.06052577  3.812858  ]\n",
      "Iter 214: error - 43.968751835732256, weights: [45.06061579  3.81284167]\n",
      "Iter 215: error - 43.968751672131944, weights: [45.06070171  3.81282609]\n",
      "Iter 216: error - 43.968751523111656, weights: [45.06078371  3.81281122]\n",
      "Iter 217: error - 43.96875138737205, weights: [45.06086197  3.81279703]\n",
      "Iter 218: error - 43.96875126372957, weights: [45.06093667  3.81278349]\n",
      "Iter 219: error - 43.96875115110608, weights: [45.06100795  3.81277056]\n",
      "Iter 220: error - 43.96875104851959, weights: [45.06107599  3.81275822]\n",
      "Iter 221: error - 43.968750955075606, weights: [45.06114092  3.81274645]\n",
      "Iter 222: error - 43.968750869959344, weights: [45.0612029   3.81273521]\n",
      "Iter 223: error - 43.96875079242864, weights: [45.06126205  3.81272448]\n",
      "Iter 224: error - 43.968750721807446, weights: [45.0613185   3.81271425]\n",
      "Iter 225: error - 43.96875065748003, weights: [45.06137237  3.81270448]\n",
      "Iter 226: error - 43.968750598885464, weights: [45.06142379  3.81269515]\n",
      "Iter 227: error - 43.96875054551283, weights: [45.06147287  3.81268625]\n",
      "Iter 228: error - 43.968750496896774, weights: [45.0615197   3.81267776]\n",
      "Iter 229: error - 43.96875045261338, weights: [45.0615644   3.81266966]\n",
      "Iter 230: error - 43.9687504122765, weights: [45.06160707  3.81266192]\n",
      "Iter 231: error - 43.968750375534434, weights: [45.06164778  3.81265454]\n",
      "Iter 232: error - 43.96875034206684, weights: [45.06168665  3.81264749]\n",
      "Iter 233: error - 43.96875031158187, weights: [45.06172373  3.81264076]\n",
      "Iter 234: error - 43.96875028381372, weights: [45.06175913  3.81263435]\n",
      "Iter 235: error - 43.96875025852026, weights: [45.06179291  3.81262822]\n",
      "Iter 236: error - 43.968750235480954, weights: [45.06182516  3.81262237]\n",
      "Iter 237: error - 43.9687502144949, weights: [45.06185593  3.81261679]\n",
      "Iter 238: error - 43.968750195379144, weights: [45.0618853   3.81261147]\n",
      "Iter 239: error - 43.96875017796697, weights: [45.06191333  3.81260638]\n",
      "Iter 240: error - 43.968750162106566, weights: [45.06194008  3.81260153]\n",
      "Iter 241: error - 43.968750147659634, weights: [45.06196561  3.8125969 ]\n",
      "Iter 242: error - 43.96875013450021, weights: [45.06198998  3.81259248]\n",
      "Iter 243: error - 43.96875012251357, weights: [45.06201324  3.81258827]\n",
      "Iter 244: error - 43.96875011159518, weights: [45.06203543  3.81258424]\n",
      "Iter 245: error - 43.968750101649825, weights: [45.06205662  3.8125804 ]\n",
      "Iter 246: error - 43.96875009259079, weights: [45.06207684  3.81257673]\n",
      "Iter 247: error - 43.968750084339106, weights: [45.06209613  3.81257324]\n",
      "Iter 248: error - 43.968750076822815, weights: [45.06211455  3.8125699 ]\n",
      "Iter 249: error - 43.968750069976366, weights: [45.06213213  3.81256671]\n",
      "Iter 250: error - 43.96875006374008, weights: [45.0621489   3.81256367]\n",
      "Iter 251: error - 43.96875005805957, weights: [45.06216491  3.81256076]\n",
      "Iter 252: error - 43.968750052885305, weights: [45.06218019  3.81255799]\n",
      "Iter 253: error - 43.96875004817217, weights: [45.06219477  3.81255535]\n",
      "Iter 254: error - 43.96875004387908, weights: [45.06220869  3.81255282]\n",
      "Iter 255: error - 43.96875003996857, weights: [45.06222197  3.81255042]\n",
      "Iter 256: error - 43.968750036406576, weights: [45.06223465  3.81254812]\n",
      "Iter 257: error - 43.96875003316203, weights: [45.06224675  3.81254592]\n",
      "Iter 258: error - 43.96875003020663, weights: [45.0622583   3.81254383]\n",
      "Iter 259: error - 43.968750027514616, weights: [45.06226932  3.81254183]\n",
      "Iter 260: error - 43.96875002506251, weights: [45.06227984  3.81253992]\n",
      "Iter 261: error - 43.96875002282894, weights: [45.06228988  3.8125381 ]\n",
      "Iter 262: error - 43.96875002079442, weights: [45.06229946  3.81253636]\n",
      "В случае использования градиентного спуска функционал ошибки составляет 43.9688\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "w = np.zeros(n)\n",
    "min_w_dist = 1e-5\n",
    "w_dist = np.inf\n",
    "max_iters = 1e3\n",
    "iters = 0\n",
    "w_list = [w.copy()]\n",
    "errors = []\n",
    "eta = 1e-2\n",
    "\n",
    "while w_dist > min_w_dist and iters < max_iters:\n",
    "    y_pred = np.dot(X,w)\n",
    "    dQ = 2/n * np.dot(X.T, y_pred - y)\n",
    "    new_w = w - eta * dQ\n",
    "    w_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    error = calc_mse(y, y_pred)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors.append(error)\n",
    "    \n",
    "    print(f'Iter {iters}: error - {error}, weights: {new_w}')\n",
    "    \n",
    "    iters += 1\n",
    "    w = new_w\n",
    "w_list = np.array(w_list)\n",
    "w_pred = w_list[-1]\n",
    "\n",
    "print(f'В случае использования градиентного спуска функционал ошибки составляет {round(errors[-1], 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
